---
title: "STA2201H Winter 2021 Assignment 1"
output: 
  pdf_document:
    number_sections: true
fontsize: 11pt
---

**Due:** 5pm, 4 February 2021

**What to hand in:** .Rmd file and the compiled pdf

**How to hand in:** Submit files via Quercus

```{r, include=FALSE}
library(tidyverse)
library(geofacet)
library(ggplot2)
library(GGally)
library(MASS)
library(AER)
library(lmtest)
library(survival)
```

# Overdispersion

Suppose that the conditional distribution of outcome $Y$ given an unobserved variable $\theta$ is Poisson, with a mean and variance $\mu\theta$, so 

$$
Y|\theta \sim  \text{Poisson}(\mu\theta)
$$

a) Assume $E(\theta) = 1$ and $Var(\theta) = \sigma^2$. Using the laws of total expectation and total variance, show $E(Y) = \mu$ and $Var(Y) = \mu (1+ \mu\sigma^2)$.

**Answer**:

Since $Y|\theta \sim \text{Poisson}(\mu \theta)$. From the property of Poisson distribution, we could derive $$E(Y|\theta) = \mu \theta, \ \ Var(Y|\theta) = \mu \theta$$
Then by the law of total expectation:
\begin{align*}
E(Y) &= E(E(Y|\theta)) &\\
&= E(\mu \theta) &\\
&= \mu E(\theta) &\\
&= \mu
\end{align*}
By the law of total variance then:
\begin{align*}
Var(Y) &= E(Var(Y|\theta)) + Var(E(Y|\theta)) &\\
&= E(\mu \theta) + Var(\mu \theta) &\\
&= \mu E(\theta) + \mu^2 Var(\theta) &\\
&= \mu + \mu^2 \sigma^2 &\\
&= \mu (1 + \mu \sigma^2)
\end{align*}


b) Assume $\theta$ is Gamma distributed with $\alpha$ and $\beta$ as shape and scale parameters, respectively. Show the unconditional distribution of $Y$ is Negative Binomial.

**Answer**:

We assumed $\theta \sim Gamma(\alpha, \beta), \ \ Y|\theta \sim \text{Poisson}(\mu \theta)$. Then for the probability density function of $y$. We would have $$f(y) = \int_0^{\infty} f(y|\theta) f(\theta)$$

\begin{align*}
f(y) &= \int_0^{\infty} f(y|\theta) f(\theta) &\\
&= \int_0^{\infty} \frac{(\mu\theta)^y e^{-\mu\theta}}{y!} \cdot \frac{\beta^{\alpha}}{\Gamma(\alpha)}\theta^{\alpha - 1}e^{-\beta\theta}d\theta &\\
&= \frac{\mu^y\beta^{\alpha}}{y! \Gamma(\alpha)} \cdot \int_0^{\infty}\theta^{y+\alpha-1}e^{-\theta(\mu + \beta)}d\theta &\\
&= \frac{\mu^y\beta^{\alpha}}{y! \Gamma(\alpha)} \cdot \frac{\Gamma(y + \alpha)}{(\mu + \beta)^{y + \alpha}} &\\
&= \frac{\Gamma(y + \alpha)}{y! \Gamma(\alpha)} \cdot (\frac{\mu}{\mu+\beta})^y \cdot (\frac{\beta}{\mu+\beta})^{\alpha} &\\
&= NB(\alpha, \frac{\mu}{\mu + \beta})
\end{align*}

We could derive $f(y)$ to be the Negative Binomial PDF as above.


c) In order for $E(Y) = \mu$ and $Var(Y) = \mu (1+ \mu\sigma^2)$, what must $\alpha$ and $\beta$ equal? 

**Answer**:
Given random variable $X \sim NB(r, p)$. We could derive $$E(X) = \frac{pr}{1-p}$$ and $$Var(X) = \frac{pr}{(1-p)^2}$$. Given the distribution we have above, we than could derive: $\frac{\mu \alpha}{\beta} = \mu$ and $\frac{\alpha\mu^2 + \alpha \beta\mu}{\beta^2} = \mu(1+\mu \sigma^2)$. Solve two equations we could have $\alpha = \beta = \frac{1}{\sigma^2}$.





\newpage

# Opioid mortality in the US

The following questions relate to the `opioids` dataset, which you can find in the `data` folder of the repo. It's an RDS file, which you can read in using `read_rds` from the `tidyverse`. There is also a `opioids_codebook.txt` file which explains each of the variables in the dataset. 

The data contains deaths due to opioids by US from 2008 to 2017. In addition, there are population counts and a few other variables of interest. The goal is to explore trends and patterns in opioid deaths over time and across geography. The outcome of interest is `deaths`. 

Please make sure to clearly explain any findings or observations you make, rather than just handing in code and output. You will be assessed not only on the code but also on how you communicate your findings with a combination of writing and analysis. 

a) Perform some exploratory data analysis (EDA) using this dataset, and briefly summarize in words, tables and charts your main observations. You may use whatever tools or packages you wish. You may want to explore the `geofacet` package, which plots US state facets in the correct geographic orientation.

**Answer**:

We found some patterns between the death rate and the other factors. Since different states could have different populations. So we use death_rate = deaths/population to describe the loss in population. Then we could find 

* The west coast often have lower death rate than the east coast and the middle area.
* Not only that, the middle area and the east coast death rates keeps increasing.
* The death rate do not have a strong correlation of the white people proportion. More likely, they have some relationships with the unemployment rates, in NV for example.
* In the middle we observe a high prescription rate but the it decreases as time goes. However, before 2015 there are some positive relationship between the presciption rate and the death rates.

```{r, echo=F}
opioids <- read_rds("/Users/siyiwei/Desktop/applied-stats-2021/data/opioids.RDS")

ggplot(opioids, aes(year, deaths/total_pop, fill = prescription_rate)) +
  geom_col() +
  coord_flip() +
  facet_geo(~ abbrev) +
  theme_bw()

ggplot(opioids, aes(year, deaths/total_pop, fill = unemp)) +
  geom_col() +
  coord_flip() +
  facet_geo(~ abbrev) +
  theme_bw()
```


b) Run a Poisson regression using `deaths` as the outcome and `tot_pop` as the offset. (remember to `log` the offset). Include the `state` variable as a factor and change the reference category to be Illinois. Investigate which variables to include, justifying based on your EDA in part a). Interpret your findings, including visualizations where appropriate. Include an analysis of which states, after accounting for other variables in the model, have the highest opioid mortality.

**Answer**:

* We first include the log(total_pop) as our offset variable and all the other potential relevant variables. Then we use StepAIC function to select the optimum variables. *The kept variables are unemp, prescription_rate, year and state.*
* The kept variables fit our initial expection in part (a). Moreover, by analyzing the coefficients. *We could find the state with the highest opioid mortality will be West Virginia (1.657).* Combine with the visualization in part(a), the prescription rate plays an important role in the death rate in West Virginia. The visualization of West Virginia specifically proved this founding.

```{r, echo=F}
opioids <- within(opioids, state <- relevel(state, ref = "Illinois"))
poisson_model <- glm(deaths ~ offset(log(total_pop)) + year + state + unemp + prescription_rate + prop_white + expected_deaths, data = opioids, family = poisson)
result <- stepAIC(poisson_model)

poisson_model <- glm(deaths ~ offset(log(total_pop)) + year + state + unemp + prescription_rate, data = opioids, family = poisson)

summary(poisson_model)

ggplot(opioids[opioids$abbrev=="WV",],aes(y=deaths,x=prescription_rate))+geom_point()+geom_smooth()
```



c) What's an issue with using population as an offset, given the limited information available in this dataset? 

**Answer**:

When use population as an offset. We potentially want to discover the relationships between deaths/total_pop and the other factors. Just as we have found before, there is a strong relation between such rate and the geographical differences (West coast and east coast).
Because of that, it is more difficult to find the relation between death and the prescription_rates. Which are our primary interests.

d) Rerun your Poisson regression using `expected_deaths` as an offset. How does this change the interpretation of your coefficients?

**Answer**:

The weights on different states decrease and the weight on prescription_rate increases as our expected. Since deaths/expected_deaths are less more likely to be affect by the geographical differences and its following impacts. Medical services, economic reasons and other factors for example.

```{r, echo=FALSE}
poisson_model <- glm(deaths ~ offset(log(expected_deaths)) + year + state + unemp + prescription_rate, data = opioids, family = poisson)

summary(poisson_model)
```


e) Investigate whether overdispersion is an issue in your current model.

**Answer**:

From the residual deviance we could see it is 13612 with 456 degrees of freedom. Consider the poisson family should be 1. However, the ratio instead is 29.85 >> 1. We use dispersion tests to verify our foundings.
Since the p-value is very small. We reject the null hypothesis and prefer the alternative hypothesis. The true alpha is greater than 0 and indicates there is an over dispersion.

```{r, echo=F}
dispersiontest(poisson_model, trafo = 1)
```


f) If overdispersion is an issue, rerun your analysis using negative binomial regression. Does this change the significance of your explanatory variables? Do a Likelihood Ratio Test to see which is the preferred model. 

**Answer**:

After we use the negative binomial regression to fit the data. We could observe much less variables are statistically significant. Which make sense since over dispersion falsify some parameters to have samller values.
We again use a likelihood ratio test to verify our findings. From the results we could conclude negative binomial regression has higher log likelihood than poisson model.
```{r, echo = F}
nega_binomial_model <- glm.nb(deaths ~ offset(log(expected_deaths)) + year + state + unemp + prescription_rate, data = opioids)

summary(nega_binomial_model)

lrtest(poisson_model, nega_binomial_model)
```


g) Summarize your findings, giving the key insights into trends in opioid mortality over time and across states, and any factors that may be associated with these changes. What other variables may be of interest to investigate in future?

**Answer**:

* From the prelimary investigation on the data. We raised couple hypothesis, the death rate are affect by geometrical differences, year, prescription_rate and unemployment rate. For the variables selection part we then verify those findings. The west coast has lower death rate across the country. Moreover, the death rate increase as time goes.
* Based on those findings. We use a negative binomial regression model with expected death as offset variable to aovid overdispersion problem and the affect by total population in states. Further more, from the coefficients we found the prescription rate has a negative effect on the populations. The unemployment rate and the time has a positive effect on the death rate instead. The differences between states are even larger. For example, West Virginia has the highest mortality rate across the country based on the coefficients. The Nebraska has the lowest.
* We could then raise some other factors might be interesting. We want to ask why the state differences could affect the mortality rate that much. To answer this question, we want to investigate the electircal health record of the patients who are prescribed across different states. Which contain more information of individual differences.  


\newpage

# Gompertz 

Gompertz hazards are of the form

$$
\lambda(t) = \alpha e^{\beta t}
$$
for $t \in [0, \infty)$ with $\alpha, \beta>0$. It is named after Benjamin Gompertz, who suggested a similar form to capture a 'law of human mortality' in 1825. 

This question uses the `ON_mortality.RDS` file in the `data` folder of the class repo. This file contains hazard rates (`hx`) and density of deaths (`dx`) by age and year for Ontario. Note that in this case, the survival times we are interested in are age. 

```{r, echo=F}
ON_mortality <- read_rds("/Users/siyiwei/Desktop/applied-stats-2021/data/ON_mortality.RDS")
ON_mortality$age <- as.integer(ON_mortality$age)
```


a) Find an expression in terms of $\alpha$ and $\beta$ for the modal age at death.

**Answer**:

To find the mode age of death. We need to find the maximum density of the potential distribution. To do that, we need to find $f(t)$ first.
\begin{align*}
f(t) &= \lambda(t) s(t) &\\
&= \alpha e^{\beta t} \cdot exp\{ -\int_0^t \lambda(x) dx \} &\\
&= \alpha e^{\beta t} \cdot exp\{ -\int_0^t \alpha e^{\beta x} dx \} &\\
&= \alpha e^{\beta t} \cdot exp\{ -(\frac{\alpha}{\beta} e^{\beta x} |_0^t) \} &\\
&= \alpha e^{\beta t} \cdot exp\{ -\frac{\alpha}{\beta}(e^{\beta t} - 1) \}
\end{align*}

Then the derivative of $log(f(x))$ could be dervived
\begin{align*}
\frac{dlog(f(t))}{dt} &= \frac{d}{dt}(log(\alpha) + \beta t - \frac{\alpha}{\beta}(e^{\beta t} - 1)) &\\
&= \beta - \alpha e^{\beta t} &\\
&= 0
\end{align*}

Then we could have optimum $\hat t = \frac{log(\beta) - log(\alpha)}{\beta}$

b) For every year, estimate $\alpha$, $\beta$ and the mode age at death.

**Answer**

The estimated Value are given below:
```{r, echo=F}
count = 1
df <- data.frame(Date=numeric(),
                 Alpha=numeric(), 
                 Beta=numeric(), 
                 Eage=numeric()) 
for(da in unique(ON_mortality$year)){
  model = lm(log(hx) ~ age, data = ON_mortality[ON_mortality$year == da,])
  alpha = exp(model$coefficients[1])
  beta = model$coefficients[2]
  mode_age = (log(beta) - log(alpha))/beta
  
  df[count,] = c(da, alpha, beta, mode_age)
  count = count + 1
  
  print(paste0("In ", da, " , The estimated alpha is ~", round(alpha,5), ",beta is ", round(beta, 3)," and mode age is ", round(mode_age,3)))
}
```


c) Create plots of $\alpha$ over time, $\beta$ over time and the mode age at death over time. Write a few sentences interpreting these results in terms of how mortality has changed over time.

**Answer** :

From the plots we could see Alpha decrease exponentially as the time increase. For Beta and the Estimated Mode Age increase linearly as the time increase.

We could say the mortality keeps decrease as the time passes. The reason is the mode age of death keeps increase.


```{r, echo=FALSE}
ggplot(df, aes(Date)) + geom_line(aes(y = Alpha, colour = "Alpha"))
ggplot(df, aes(Date)) + geom_line(aes(y = Beta, colour = "Beta"))
ggplot(df, aes(Date)) + geom_line(aes(y = Eage, colour = "Estimated_Mode_Age"))
```


\newpage 
# Infant mortality 

In this part we will be looking at the infant mortality data set. This is in the `data` folder called `infant.RDS`.This dataset contains individual-level data (i.e., every row is a death) on deaths in the first year of life for the US 2012 birth cohort. A second dataset you will be using for this question is `births.RDS`, which tabulates the total number of live births for the US 2012 birth cohort by race and prematurity. Descriptions of each variable can be found in the `infant_mortality_codebook.txt` file. 

The goal is to investigate differences in ages at death by race of mother and prematurity (from extremely preterm to full-term).

```{r, echo=F}
infant <- read_rds("/Users/siyiwei/Desktop/applied-stats-2021/data/infant.RDS")
births <- read_rds("/Users/siyiwei/Desktop/applied-stats-2021/data/births.RDS")
#Infant with age 0 means dead in hours. Corrected by adding 0.5
infant[infant$aged==0, 2] <- infant[infant$aged==0, 2] + 0.5
```


a) The infant mortality rate (IMR) is defined as the number of deaths in the first year divided by the number of live births. Calculate the IMR for the non-Hispanic black (NHB) and non-Hispanic white (NHW) populations. What is the ratio of black-to-white mortality?

**Answer**:

The NHB IMR is about 0.11 and the NHW IMR is about 0.005, the ratio of black to white mortality will be about 2.21.

```{r, echo = F}
NHB_IMR = sum(infant[infant$race=="NHB", 2] <= 365)/sum(births[births$race=="NHB", 3])
NHW_IMR = sum(infant[infant$race=="NHW", 2] <= 365)/sum(births[births$race=="NHW", 3])
print(NHB_IMR)
print(NHW_IMR)
print(NHB_IMR/NHW_IMR)
```


b)  Calculate the Kaplan-Meier estimate of the survival function for each race and prematurity category (i.e. you should end up with 8 sets of survival functions). Also calculate the standard error of the estimates of the survival function. Note that to calculate the survival function you will need to incorporate information from the births file, not just the deaths (otherwise it will look like everyone died).

**Answer**;

Since the table is too large for display. I have hide the code and the estimations. More details are in Rmd file and the visualization will be in part (c)

```{r, echo=F}
store_df = data.frame(race = character(),
                      prem = character(),
                      estimate = numeric(),
                      std = numeric(),
                      time = numeric())
for(cat in unique(infant$race)){
  for(pre in unique(infant$prematurity)){
    deaths = cbind(infant[infant$race == cat & infant$prematurity == pre, 2],
                   status = 1)
    tem <- data.frame(aged = max(deaths$aged), status = 0)
    alive = rbind(tem, tem[rep(1,births[births$race==cat & births$prematurity == pre,3] - dim(deaths)[1] - 1),])
    df_partB = rbind(deaths, alive)
    
    #Train the model
    model <- survfit(Surv(aged, event = status) ~ 1, data = df_partB)
    
    #Create the new tem dataframe
    tem2 = data.frame(race = cat,prem = pre,estimate = 0,std = 0, time=0)
    tem2 <- rbind(tem2, tem2[rep(1, length(model$surv)-1),])
    tem2$estimate = model$surv
    tem2$std = model$std.err
    tem2$time = model$time
    
    #concat to store
    store_df <- rbind(store_df, tem2)
  }
}
```


c)  Plot your results from b), showing the estimate and +/- 2 standard errors. What the plot should look like: NHB and NHW survival curves on the one plot; one separate facet per prematurity category. Note that the survival curves are very different by prematurity category, so it might help to make the y axes different scales for each category (e.g. `facet_grid(prematurity~., scales = "free_y")`).

**Answer**:

The visulizations could be viewed below:

```{r, echo=F}
p <- ggplot(store_df[store_df$race == "NHW",],
       aes(x = time,
           y = estimate)) +
  # Add a ribbon with the confidence band
  geom_smooth(
    aes(
      # lower and upper bound of the ribbon
      ymin = estimate - 2*std, ymax = estimate + 2*std,
      # Different colour for men/women
      fill = prem, colour = prem
      ), stat = "identity") +
  facet_grid(prem~., scales = "free_y") + 
  xlab("Time") +
  ylab("Survive Prob Estimate") + 
  ggtitle("Survival Analysis with NHW")
  
p

p <- ggplot(store_df[store_df$race == "NHB",],
       aes(x = time,
           y = estimate)) +
  # Add a ribbon with the confidence band
  geom_smooth(
    aes(
      # lower and upper bound of the ribbon
      ymin = estimate - 2*std, ymax = estimate + 2*std,
      # Different colour for men/women
      fill = prem, colour = prem
      ), stat = "identity") +
  facet_grid(prem~., scales = "free_y") + 
  xlab("Time") +
  ylab("Survive Prob Estimate") + 
  ggtitle("Survival Analysis with NHB")
  
p
```

d)  On first glance, your plots in c) might contradict what you expected based on a). Why is the IMR so much higher for the NHB population, even though for (most) prematurity groups, the survival curves are reasonably similar to the NHW population?

**Answer**:

The IMR ratio are measured as a total. However, the plots are measured in time. So across different time slot there may be a little difference. But stack such effects may cause a significant different in the final IMR. By comparing the two visualizations we could conclude NHW has slightly higher survival rate than NHB across all four categories.


e)  Now consider fitting a piece-wise constant hazards model to the survival time data with cut-points at 1, 7, 14, 28, 60, 90 and 120 days. Consider a model that has race and prematurity as covariates. You *could* fit this model just using the deaths data, but the direction of the sign of the coefficient on race would be misleading. Why is that?

**Answer**:

We could fit the model using only death data. Since we already know NHW has lower IMR ratio so the sign here is not reasonable for sure. I guess the reason might be exclusion of the birth data. By doing that we exclude the effect of total population. There might be more infants in NHW than NHB so the death speed might be higher.
By summary the data we could confirm the result. NHW has 10617 and NHB only have 6407 people.

```{r, echo = F}
cutpoints = c(1, 7, 14, 28, 60, 90, 120)
infant$status = 1

PW_split <- survSplit(formula = Surv(aged, event = status) ~ . ,data = infant, cut = cutpoints) %>%
  as_tibble() %>%
  mutate(interval = factor(tstart),
         interval_length = aged - tstart)

PW_model <- glm(status ~ offset(log(interval_length)) - 1 + interval + race + prematurity, data = PW_split, family = "poisson")

summary(PW_model)

```


f) Fit a piece-wise constant hazards model with cut-points as specified in e). Note given the large numbers of births/deaths, it will be much easier to run the model based on the tabulated deaths/exposures by age at death, rather than individual-level data. Include as covariates race and prematurity, and allow the hazard ratios of each to vary by interval. Note that you may want to investigate interaction terms. Calculate the hazard of dying in the first interval (0-1 day) of extremely preterm babies born to NHB mothers. In addition, give the hazard ratios of dying for:
    
    1) extremeley preterm babies to NHW mothers compared to extremeley preterm babies to NHB mothers in the first interval (0-1 days).
    2) full-term babies to NHB mothers compared to extremeley preterm babies to NHB mothers in the first interval (0-1 days).
    3) full-term babies to NHB mothers compared to extremeley preterm babies to NHB mothers in the last interval (120-365 days).
    4) full-term babies to NHW mothers compared to full-term babies to NHB mothers in the last interval (120-365 days).
    
**Answer**:
To better answer this question, we need to calculate the harzard of the following conditions, the:

* (0-1 day) of extremely preterm babies born to NHW mothers : 1.125
* (0-1 day) of extremely preterm babies born to NHB mothers : 1.067
* (0-1 day) of full preterm babies born to NHB mothers : 0.0998
* (120-365 day) of full preterm babies born to NHB mothers : 0.0123
* (120-365 day) of extremely preterm babies born to NHB mothers : 0.0139
* (120-365 day) of full preterm babies born to NHW mothers : 0.0113

Then we could answer the main question: The hazard of dying in the first interval (0-1 day) of extremely preterm babies born to NHB mothers is ~1.067.
Then for the following question:

1. 1.125/1.067 = 1.054
1. 0.0998/1.067 = 0.0935
1. 0.0123/0.0139 = 0.884
1. 0.0113/0.0123 = 0.918
    
```{r, echo = F}
condition = infant[infant$race == "NHW" & infant$prematurity == "full-term",]

PW_split <- survSplit(formula = Surv(aged, event = status) ~ . ,data = condition, cut = cutpoints) %>%
  as_tibble() %>%
  mutate(interval = factor(tstart),
         interval_length = aged - tstart)

PW_model <- glm(status ~ offset(log(interval_length)) - 1 + interval, data = PW_split, family = "poisson")

summary(PW_model)
exp(coef(PW_model))
unique(infant$prematurity)
```


g) Fit a piecewise hazards model to the whole population (i.e. just have `interval` as a covariate) and calculate the survival curve. Compare to the KM estimate from b) by plotting the two curves on the one graph. The fit should be fairly reasonable, so if it's not there could be an issue in your part f) model.

**Answer**:

Since in this question we mainly use the deaths data. So for the KM curve we will keep use deaths data.
We could see the curve fit almost the same.

```{r, echo = F}
infant$status = 1
PW_split <- survSplit(formula = Surv(aged, event = status) ~ . ,data = infant, cut = cutpoints) %>%
  as_tibble() %>%
  mutate(interval = factor(tstart),
         interval_length = aged - tstart)

PW_model <- glm(status ~ offset(log(interval_length)) - 1 + interval, data = PW_split, family = "poisson")

model <- survfit(Surv(aged, event = status) ~ 1, data = infant)

cuts <- c(0, cutpoints, max(infant$aged))
survival_prob <- function(lambdas,
                     cuts, # start and end times that lambdas refers to, starting at 0 and ending at max
                     ## observation time of interest,
                     ## thus length is one more than length of lambda
                     neval = 100 # at how many points do you want to evaluate S(t) within each interval?
                     ){
  lengthintervals <- rep((cuts[-1] - cuts[-length(cuts)])/neval, each = neval)
  t_seq <- c(0, cumsum(lengthintervals))
  cumulative_hazard <- cumsum(lengthintervals*rep(lambdas, each  = neval))
  surv_probs <- c(1, exp(-cumulative_hazard))
  return(tibble(time = t_seq, surv = surv_probs ))
}

df_surv <- survival_prob(lambdas = exp(coef(PW_model)), 
              cuts = cuts)
KM_line <- tibble(time = model$time, surv = model$surv)

ggplot(aes(time, surv), data = df_surv) + geom_line() +
  geom_line(aes(time, surv), data = KM_line) +
  ggtitle("Proportion of Survive") + 
  xlab("days") + ylab("Surv")+
  scale_color_manual(values = c("darkred", "steelblue"))+
  theme_bw(base_size = 14)
```




